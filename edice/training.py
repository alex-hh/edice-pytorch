from collections import defaultdict
import time
import torch

from edice.utils import isnumeric


class BaseMetricsContainer:

    def update(self):
        raise NotImplementedError()

    def values(self):
        raise NotImplementedError()

    def print_values(self, epoch, batch_ix):
        running_metrics = self.values()
        running_metrics_msg = "  ".join([
                    f"{m}: {v} " 
                    for m, v in running_metrics.items()
                ])
        print(f"[{epoch or -1:d}, {batch_ix+1:5d}, ({self.total_seen}) datapoints] "
              + running_metrics_msg, flush=True)


class ScalarAverageMetricsContainer(BaseMetricsContainer):

    """Loss-associated metrics which should be averaged over samples.

    values() returns running_metrics.
    """

    def __init__(self):
        self.total_seen = 0
        self.metrics_totals = defaultdict(int)
        self.metrics_total_seen = defaultdict(int)

    def update(self, batch_metrics, batch_size):
        for m, v in batch_metrics.items():
            if isinstance(v, torch.Tensor):
                # we don't want tensors as they will create computation graphs
                # https://blog.paperspace.com/pytorch-memory-multi-gpu-debugging/
                # raise ValueError()
                v = v.item()
            if isnumeric(v):
                self.metrics_totals[m] += (v*batch_size)
                self.metrics_total_seen[m] += batch_size

        self.total_seen += batch_size

    def values(self):
        return {m: v/self.metrics_total_seen[m] for m, v in self.metrics_totals.items()}


def test_loop(
    learner,
    data_loader,
    verbose=False,
    prefix="",
):
    """Test loop.

    Steps through all batches in data loader and accumulates metrics.
    N.B. only accumulates metrics generated by calling learner.test_step;
    other metrics may require calls to different learner methods and
    should be handled separately as evaluators.
    """
    learner.test_begin()
    metrics_container = ScalarAverageMetricsContainer()

    for i, batch in enumerate(data_loader):
        # TODO - need to handle this differently
        batch_size = learner.get_batch_size(batch)

        batch_metrics = learner.test_step(
            batch,
        )  # TODO handle the effective_batch_size correction outside of train step
        batch_metrics = {f"val/{prefix}" + k: v for k, v in batch_metrics.items()}
        # SEQUENCE / DATAPOINT LEVEL METRICS
        metrics_container.update(batch_metrics, batch_size)

    metrics = (
        metrics_container.values()
    )  # n.b. dont add time to avoid conflict. or if do prefix with val.

    return metrics


def epoch_train(
    learner,
    data_loader,
    verbose=False,
    test_run=False,
    epoch=None,
    batch_log_freq=500,
    logger=None,
):
    """Single epoch training loop. Assumes learner handles gradient updates.

    Steps through all batches in data loader, updates parameters,
    accumulates and prints metrics, and writes model checkpoints.
    """
    t0 = time.time()
    learner.epoch_begin()

    # TODO add stateful metrics to learner?
    metrics_container = ScalarAverageMetricsContainer()

    for i, batch in enumerate(data_loader):
        batch_metrics = learner.train_step(batch)

        # SEQUENCE / DATAPOINT LEVEL METRICS
        batch_size = learner.get_batch_size(batch)
        metrics_container.update(batch_metrics, batch_size)

        if batch_log_freq is not None and (i % batch_log_freq == (batch_log_freq - 1)) or test_run:
            metrics_container.print_values(epoch, i)

    t1 = time.time()

    end_metrics = {f"train/{k}": v for k, v in metrics_container.values().items()}
    end_metrics["train/time(s)"] = t1 - t0

    return end_metrics


def train(
    learner,
    train_loader,
    epochs=100,
    val_freq=1,
    logger=None,
    batch_size=100,
    validation_loader=None,
):
    learner.train_begin()  # consider whether or not we want this - resume...
    hist = []
    for epoch in range(epochs):
        metrics = epoch_train(
            learner,
            train_loader,
            epoch=epoch,
            batch_log_freq=None,
        )
        is_val_epoch = epoch % val_freq == 0 or epoch == epochs-1
        if val_freq is not None and validation_loader is not None and is_val_epoch:
            with torch.no_grad():
                metrics.update(
                    test_loop(
                        learner,
                        validation_loader,
                    )
                )

        hist.append(metrics)
        if logger is not None:
            logger.log(epoch, metrics, batch=-1)
    return hist

