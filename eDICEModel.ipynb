{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from edice import loggers\n",
    "from edice.data.datasets import EpigenomeSliceDataset, EpigenomeSliceWithTargets\n",
    "from edice.data.dataset_config import load_dataset\n",
    "from edice.model.edice import eDICEModel, eDICE\n",
    "from edice.training import train\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592724c0",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* check masking\n",
    "* check inputs construction\n",
    "* check MSE dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9765e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = load_dataset(\"PredictdSample\")\n",
    "n_cells, n_assays = len(data_module.cells), len(data_module.assays)\n",
    "print(f\"n cells {n_cells}, n assays {n_assays}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5191b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = eDICEModel(\n",
    "    n_cells,\n",
    "    n_assays,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7549a0",
   "metadata": {},
   "source": [
    "# 2. Stepping through the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19fa946",
   "metadata": {},
   "source": [
    "### 2.1 Constructing a C x A matrix from a list of tracks\n",
    "\n",
    "Where C is number of cells, A is number of assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e22f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edice.model.encoders import InputExpander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdf4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "cell_ids = [data_module.cell2id[data_module.get_track_cell(t)] for t in data_module.splits[\"train\"]]\n",
    "assay_ids = [data_module.assay2id[data_module.get_track_assay(t)] for t in data_module.splits[\"train\"]]\n",
    "vals = torch.rand(batch_size, len(data_module.splits[\"train\"]))\n",
    "batch_cell_ids = torch.from_numpy(np.array(cell_ids)).expand(3,-1)\n",
    "batch_assay_ids = torch.from_numpy(np.array(assay_ids)).expand(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2mat = InputExpander(n_cells, n_assays)\n",
    "obs = vec2mat(vals, batch_cell_ids, batch_assay_ids)\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_assay_vals(mat, cell):\n",
    "    assert mat.ndim ==2  # no batch dim\n",
    "    cell_id = data_module.cell2id[cell]\n",
    "    id2assay = {v: k for k, v in data_module.assay2id.items()}\n",
    "    cell_vec = mat[cell_id]\n",
    "    d = {id2assay[i]: cell_vec[i] for i in range(mat.shape[-1])}\n",
    "    return d\n",
    "\n",
    "print(\n",
    "    {k: v for k, v in cell_assay_vals(obs[0], \"E001\").items() if v != 0},\n",
    "    [t for t in data_module.splits[\"train\"] if data_module.get_track_cell(t) == \"E001\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f80fefc",
   "metadata": {},
   "source": [
    "TODO: check that these actually make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54b9f8",
   "metadata": {},
   "source": [
    "# 3. Training on sample data\n",
    "\n",
    "### 3.1 Setup and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ab768",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_splits = [\"train\"]\n",
    "val_split = \"val\"\n",
    "n_targets = 120\n",
    "lr = 3e-4\n",
    "transformation = \"arcsinh\"\n",
    "batch_size = 256\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "edice = eDICE(\n",
    "    model,\n",
    "    optim,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    n_targets=n_targets,\n",
    ")\n",
    "logger = loggers.StdOutLogger(log_freq=1)\n",
    "\n",
    "train_tracks = [t for split in train_splits for t in data_module.splits[split]]\n",
    "train_tracks, train_cell_ids, train_assay_ids = data_module.prepare_data(train_tracks)\n",
    "if val_split is not None:\n",
    "    val_tracks = data_module.splits[val_split]\n",
    "    val_tracks, val_cell_ids, val_assay_ids = data_module.prepare_data(val_tracks)\n",
    "    data = EpigenomeSliceWithTargets(\n",
    "        train_tracks,\n",
    "        train_cell_ids,\n",
    "        train_assay_ids,\n",
    "        val_tracks,\n",
    "        val_cell_ids,\n",
    "        val_assay_ids,\n",
    "        transform=transformation,\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "else:\n",
    "    data = EpigenomeSliceDataset(\n",
    "        train_tracks,\n",
    "        train_cell_ids,\n",
    "        train_assay_ids,\n",
    "        transform=transformation,\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ed072",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2Â Let's visualise the training data\n",
    "\n",
    "Note we first transform the data back to the original log 10 p-value\n",
    "scale before visualising using np.sinh\n",
    "\n",
    "#### TODO: annotate plots with track names and slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_track_slices = 5\n",
    "slice_size = 4000\n",
    "train_X = train_data.X\n",
    "num_bins, num_tracks = train_X.shape\n",
    "print(f\"Train data (num bins: {num_bins}, num tracks {num_tracks})\")\n",
    "print(f\"Val data (num bins: {val_data.X.shape[0]}, num tracks {val_data.X.shape[1]})\")\n",
    "\n",
    "for i in range(num_track_slices):\n",
    "    track_ix = np.random.choice(num_tracks)\n",
    "    start_ix = np.random.choice(num_bins - slice_size)\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(slice_size), np.sinh(train_X[start_ix:start_ix+slice_size,track_ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c43cab",
   "metadata": {},
   "source": [
    "TODO: add a correlation evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train(\n",
    "    edice,\n",
    "    train_loader,\n",
    "    epochs=20,\n",
    "    logger=logger,\n",
    "    batch_size=batch_size,\n",
    "    validation_loader=val_loader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
